{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /home/aishutin/.cache/torch/checkpoints/vgg16-397923af.pth\n",
      "100%|██████████| 528M/528M [05:10<00:00, 1.78MB/s] \n"
     ]
    }
   ],
   "source": [
    "vgg = models.vgg16(pretrained=True)  # This may take a few minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ConvTranspose2d_DEFAULT_KERNEL_DIM_SIZE = 5\n",
    "ConvTranspose2d_DEFAULT_MAX_STRIDE = 4\n",
    "ConvTranspose2d_DEFAULT_MAX_DILATION = 4\n",
    "ConvTranspose2d_DEFAULT_MAX_INP_PADDING = 4\n",
    "ConvTranspose2d_DEFAULT_MAX_OUT_PADDING = 4\n",
    "def calc_parameters(lay):\n",
    "    total = 0\n",
    "    for tensor in lay.parameters():\n",
    "        curr = 1\n",
    "        for el in tensor.shape:\n",
    "            curr *= el\n",
    "        total += curr\n",
    "    return total\n",
    "\n",
    "def choose_parameters_in_ConvTranspose2d_space(input_shape, output_shape, kernel_dims=None, symmetric=True):\n",
    "    batch_size, cin, hin, win = input_shape\n",
    "    batch_size, cout, hout, wout = output_shape\n",
    "    \n",
    "    if kernel_dims is None:\n",
    "        kernel_dims = range(1, 1 + ConvTranspose2d_DEFAULT_KERNEL_DIM_SIZE)\n",
    "    \n",
    "    input_ex = torch.randn((1, cin, hin, win))\n",
    "    strides = range(1, ConvTranspose2d_DEFAULT_MAX_STRIDE + 1)\n",
    "    dilations = range(1, 1 + ConvTranspose2d_DEFAULT_MAX_DILATION)\n",
    "    inp_pads = range(0, ConvTranspose2d_DEFAULT_MAX_INP_PADDING + 1)\n",
    "    out_pads = range(0, ConvTranspose2d_DEFAULT_MAX_OUT_PADDING + 1)\n",
    "    \n",
    "    configurations = []\n",
    "    \n",
    "    for stride1 in strides:\n",
    "        for stride2 in strides:\n",
    "            if stride1 != stride2 and symmetric:\n",
    "                continue\n",
    "            for dil1 in dilations:\n",
    "                for dil2 in dilations:\n",
    "                    if dil1 != dil2 and symmetric:\n",
    "                        continue\n",
    "                    for kdim1 in kernel_dims:  \n",
    "                        for kdim2 in kernel_dims:\n",
    "                            if kdim1 != kdim2 and symmetric:\n",
    "                                continue\n",
    "                            for ipad1 in inp_pads:\n",
    "                                for ipad2 in inp_pads:\n",
    "                                    if ipad1 != ipad2 and symmetric:\n",
    "                                        continue\n",
    "                                    for opad1 in out_pads:\n",
    "                                        for opad2 in out_pads:\n",
    "                                            if opad1 != opad2 and symmetric:\n",
    "                                                continue\n",
    "                                            params =  { 'in_channels': cin, \n",
    "                                                        'out_channels': cout,\n",
    "                                                        'kernel_size': (kdim1, kdim2),\n",
    "                                                        'stride': (stride1, stride2),\n",
    "                                                        'dilation': (dil1, dil2),\n",
    "                                                        'padding': (ipad1, ipad2),\n",
    "                                                        'output_padding': (opad1, opad2)}\n",
    "                                            \n",
    "                                            try:\n",
    "                                                lay = torch.nn.ConvTranspose2d(**params)\n",
    "                                                if lay(input_ex).shape != (1, cout, hout, wout):\n",
    "                                                    continue\n",
    "                                            except Exception as exp:\n",
    "                                                continue\n",
    "                                            \n",
    "\n",
    "                                            configurations.append((calc_parameters(lay), params))\n",
    "    configurations.sort(key=lambda x: x[0])\n",
    "    return [el[1] for el in configurations]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_parameters_in_Linear_space(input_shape, output_shape):\n",
    "    return [{'in_features': input_shape[-1], 'out_features': output_shape[-1]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (1, 1), 'stride': (1, 1), 'dilation': (1, 1), 'padding': (0, 0), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (1, 1), 'stride': (1, 1), 'dilation': (2, 2), 'padding': (0, 0), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (1, 1), 'stride': (1, 1), 'dilation': (3, 3), 'padding': (0, 0), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (1, 1), 'stride': (1, 1), 'dilation': (3, 3), 'padding': (1, 1), 'output_padding': (2, 2)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (1, 1), 'stride': (1, 1), 'dilation': (4, 4), 'padding': (0, 0), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (1, 1), 'stride': (1, 1), 'dilation': (4, 4), 'padding': (1, 1), 'output_padding': (2, 2)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (2, 2), 'stride': (1, 1), 'dilation': (2, 2), 'padding': (1, 1), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (2, 2), 'stride': (1, 1), 'dilation': (3, 3), 'padding': (2, 2), 'output_padding': (1, 1)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (2, 2), 'stride': (1, 1), 'dilation': (4, 4), 'padding': (2, 2), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (2, 2), 'stride': (1, 1), 'dilation': (4, 4), 'padding': (3, 3), 'output_padding': (2, 2)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (3, 3), 'stride': (1, 1), 'dilation': (1, 1), 'padding': (1, 1), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (3, 3), 'stride': (1, 1), 'dilation': (2, 2), 'padding': (2, 2), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (3, 3), 'stride': (1, 1), 'dilation': (3, 3), 'padding': (3, 3), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (3, 3), 'stride': (1, 1), 'dilation': (3, 3), 'padding': (4, 4), 'output_padding': (2, 2)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (3, 3), 'stride': (1, 1), 'dilation': (4, 4), 'padding': (4, 4), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (4, 4), 'stride': (1, 1), 'dilation': (2, 2), 'padding': (3, 3), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (5, 5), 'stride': (1, 1), 'dilation': (1, 1), 'padding': (2, 2), 'output_padding': (0, 0)}\n",
      "{'in_channels': 64, 'out_channels': 3, 'kernel_size': (5, 5), 'stride': (1, 1), 'dilation': (2, 2), 'padding': (4, 4), 'output_padding': (0, 0)}\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, 3, 32, 32)\n",
    "conv = torch.nn.Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "output = conv(input)\n",
    "for el in choose_parameters_in_ConvTranspose2d_space(output.shape, input.shape):\n",
    "    print(el)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
